{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m W&B installed but not logged in.  Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import transformers\n",
    "import tokenizers\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm.autonotebook import tqdm\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from transformers import AdamW\n",
    "\n",
    "MAX_LEN=192\n",
    "EPOCHS=5\n",
    "TRAIN_BATCH_SIZE=64\n",
    "VALID_BATCH_SIZE=16\n",
    "BERT_PATH=\"../input/roberta-base\"\n",
    "MODEL_PATH = \"model.bin\"\n",
    "TOKENIZER=tokenizers.ByteLevelBPETokenizer(\n",
    "    vocab_file=f'{BERT_PATH}/vocab.json',\n",
    "    merges_file=f'{BERT_PATH}/merges.txt',\n",
    "    lowercase=True,\n",
    "    add_prefix_space=True\n",
    ")\n",
    "def process_data(tweet, selected_text, sentiment, max_len, tokenizer):\n",
    "    selected_text=' '.join(str(selected_text).split())\n",
    "    tweet= \" \".join(str(tweet).split())\n",
    "    len_st = len(str(selected_text))\n",
    "    idx0 = None\n",
    "    idx1 = None\n",
    "    for ind in (i for i, e in enumerate(str(tweet)) if e == selected_text[0]):\n",
    "        if tweet[ind: ind+len_st] == selected_text:\n",
    "            idx0 = ind\n",
    "            idx1 = ind + len_st - 1\n",
    "            break\n",
    "\n",
    "    char_targets = [0] * len(tweet)\n",
    "    if idx0 != None and idx1 != None:\n",
    "        for ct in range(idx0, idx1 + 1):\n",
    "            char_targets[ct] = 1\n",
    "    \n",
    "    tok_tweet = tokenizer.encode(tweet)\n",
    "    ids_orig = tok_tweet.ids\n",
    "    tweet_offset = tok_tweet.offsets\n",
    "    \n",
    "    target_idx = []\n",
    "    for j, (offset1, offset2) in enumerate(tweet_offset):\n",
    "        if sum(char_targets[offset1: offset2]) > 0:\n",
    "            target_idx.append(j)\n",
    "    orig_text=tweet\n",
    "    target_start = target_idx[0]\n",
    "    target_end = target_idx[-1]\n",
    "\n",
    "    sentiment_id = {\n",
    "        'positive': 1313,\n",
    "        'negative': 2430,\n",
    "        'neutral': 7974\n",
    "    }\n",
    "    \n",
    "    ids = [0] + [sentiment_id[sentiment]] + [2] + [2] + ids_orig + [2]\n",
    "    token_type_ids = [0, 0, 0, 0] + [0] * (len(ids_orig) + 1)\n",
    "    mask = [1] * len(token_type_ids)\n",
    "    tweet_offset = [(0, 0)] * 4 + tweet_offset + [(0, 0)]\n",
    "    target_start += 4\n",
    "    target_end += 4\n",
    "\n",
    "    padding_length = max_len - len(ids)\n",
    "    if padding_length > 0:\n",
    "        ids = ids + ([0] * padding_length)\n",
    "        mask = mask + ([0] * padding_length)\n",
    "        token_type_ids = token_type_ids + ([0] * padding_length)\n",
    "        tweet_offset = tweet_offset + ([(0, 0)] * padding_length)\n",
    "    return {\n",
    "        'ids': ids,\n",
    "        'text_offset': tweet_offset,\n",
    "        'token_type_ids': token_type_ids,\n",
    "        'ids_orig': ids_orig,\n",
    "        'masks': mask,\n",
    "        'target_end': target_end,\n",
    "        'target_start': target_start,\n",
    "        'sentiment': sentiment,\n",
    "        'selected_text': str(selected_text),\n",
    "        'orig_text': orig_text \n",
    "    }\n",
    "class BertData:\n",
    "    def __init__(self,text,selected_text,sentiment):\n",
    "        self.text = text\n",
    "        self.selected_text = selected_text\n",
    "        self.sentiment = sentiment\n",
    "        self.max_len=MAX_LEN\n",
    "        self.tokenizer=TOKENIZER\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.text)\n",
    "\n",
    "    def __getitem__(self,item):\n",
    "        data = process_data(self.text[item],\n",
    "                            self.selected_text[item],\n",
    "                            self.sentiment[item],\n",
    "                            self.max_len,\n",
    "                            self.tokenizer)\n",
    "        return {\n",
    "        'ids': torch.tensor (data['ids'], dtype=torch.long),\n",
    "        'text_offset': torch.tensor (data['text_offset'], dtype=torch.long),\n",
    "        'token_type_ids': torch.tensor (data['token_type_ids'], dtype=torch.long),\n",
    "        'masks': torch.tensor (data['masks'], dtype=torch.long),\n",
    "        'target_end': torch.tensor (data['target_end'], dtype=torch.long),\n",
    "        'target_start': torch.tensor (data['target_start'], dtype=torch.long),\n",
    "        'sentiment': data['sentiment'],\n",
    "        'selected_text': data['selected_text'],\n",
    "        'orig_text': data['orig_text'] \n",
    "    }\n",
    "class bertmodel(transformers.BertPreTrainedModel):\n",
    "    def __init__(self, conf):\n",
    "        super(bertmodel, self).__init__(conf)\n",
    "        self.bert = transformers.RobertaModel.from_pretrained(BERT_PATH, config=conf)\n",
    "        self.dropout= nn.Dropout(0.5)\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm1d(num_features=192)\n",
    "        self.bn2 = nn.BatchNorm1d(num_features=192)\n",
    "        \n",
    "        \n",
    "        self.c1=nn.Conv1d(768,768,2)\n",
    "        self.c11=nn.Conv1d(768,256,2)\n",
    "        self.c111=nn.Conv1d(256,64,2)\n",
    "        self.c2=nn.Conv1d(768,768,2)\n",
    "        self.c22=nn.Conv1d(768,256,2)\n",
    "        self.c222=nn.Conv1d(256,64,2)\n",
    "        self.Leaky= nn.ReLU(0.3)\n",
    "        self.i0=nn.Linear(64,1)\n",
    "        self.i1=nn.Linear(64,1)\n",
    "        nn.init.normal_(self.i0.bias, 0)\n",
    "        nn.init.normal_(self.i0.weight, std=0.02)\n",
    "        nn.init.normal_(self.i1.bias, 0)\n",
    "        nn.init.normal_(self.i1.weight, std=0.02)\n",
    "        \n",
    "\n",
    "    def forward(self, ids, masks, token_type_ids):\n",
    "        _,_,out=self.bert(\n",
    "            ids,\n",
    "            attention_mask=masks,\n",
    "            token_type_ids=token_type_ids\n",
    "        )\n",
    "        out = torch.stack([out[-1], out[-2], out[-3], out[-4]])\n",
    "        out = torch.mean(out, 0)\n",
    "\n",
    "        #out=torch.cat((out[-1],out[-2]), dim=-1)\n",
    "        out=self.dropout(out)\n",
    "        out = nn.functional.pad(out.transpose(1,2), (1, 0))\n",
    "\n",
    "        out1 = self.c1(out).transpose(1,2)\n",
    "        out1=self.Leaky(self.bn1 (out1))\n",
    "        out1 = self.c11(nn.functional.pad(out1.transpose(1,2), (1, 0))).transpose(1,2)\n",
    "        out1=self.Leaky(self.bn2 (out1))\n",
    "        out1 = self.c111(nn.functional.pad(out1.transpose(1,2), (1, 0))).transpose(1,2)\n",
    "        out1=self.Leaky(self.bn2 (out1))\n",
    "        \n",
    "        out2 = self.c2(out).transpose(1,2)\n",
    "        out2=self.Leaky(self.bn1 (out2))\n",
    "        out2 = self.c22(nn.functional.pad(out2.transpose(1,2), (1, 0))).transpose(1,2)\n",
    "        out2=self.Leaky(self.bn2 (out2))\n",
    "        out2 = self.c222(nn.functional.pad(out2.transpose(1,2), (1, 0))).transpose(1,2)\n",
    "        out2=self.Leaky(self.bn2 (out2))\n",
    "        start_logits = self.i0(self.dropout(out1)).squeeze(-1)\n",
    "        end_logits = self.i1(self.dropout(out2)).squeeze(-1)\n",
    "        return start_logits, end_logits\n",
    "\n",
    "\n",
    "def loss_fn(start_logits, end_logits, start_pos, end_pos):\n",
    "    loss= nn.CrossEntropyLoss()\n",
    "    start_loss=loss(start_logits, start_pos)\n",
    "    end_loss=loss(end_logits, end_pos)\n",
    "    total_loss=(start_loss+end_loss)\n",
    "    return total_loss\n",
    "def jaccard(str1, str2): \n",
    "    a = set(str1.lower().split()) \n",
    "    b = set(str2.lower().split())\n",
    "    c = a.intersection(b)\n",
    "    return float(len(c)) / (len(a) + len(b) - len(c))\n",
    "\n",
    "def calculate_jaccard(orig_text, sentiment, target_str, ind_start, ind_end, offsets, verbose=False):\n",
    "    filtered_out=''\n",
    "    if ind_start>ind_end:\n",
    "        filtered_out=orig_text\n",
    "    \n",
    "    for i in range(ind_start, ind_end+1):\n",
    "        filtered_out+=orig_text[offsets[i][0]:offsets[i][1]]\n",
    "        if (i+1)<len(offsets) and offsets[i][1]<offsets[i+1][0]:\n",
    "            filtered_out+=' '\n",
    "    if sentiment=='neutral' or len(str(orig_text).split())<2:\n",
    "        filtered_out=orig_text\n",
    "    \n",
    "    jac=jaccard(str(target_str).strip(),str(filtered_out).strip())\n",
    "    return jac, filtered_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bertmodel(\n",
       "  (bert): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=0)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (bn1): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (bn2): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (c1): Conv1d(768, 768, kernel_size=(2,), stride=(1,))\n",
       "  (c11): Conv1d(768, 256, kernel_size=(2,), stride=(1,))\n",
       "  (c111): Conv1d(256, 64, kernel_size=(2,), stride=(1,))\n",
       "  (c2): Conv1d(768, 768, kernel_size=(2,), stride=(1,))\n",
       "  (c22): Conv1d(768, 256, kernel_size=(2,), stride=(1,))\n",
       "  (c222): Conv1d(256, 64, kernel_size=(2,), stride=(1,))\n",
       "  (Leaky): ReLU(inplace=True)\n",
       "  (i0): Linear(in_features=64, out_features=1, bias=True)\n",
       "  (i1): Linear(in_features=64, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test=pd.read_csv('../input/tweet-sentiment-extraction/test.csv')\n",
    "df_test.loc[:,'selected_text']=df_test.text.values\n",
    "device='cuda'\n",
    "model_config=transformers.BertConfig.from_pretrained(BERT_PATH)\n",
    "model_config.output_hidden_states=True\n",
    "model1=bertmodel(conf=model_config)\n",
    "model1.to(device)\n",
    "model1.load_state_dict(torch.load('../input/roberta-base-cnn-using-pytorch/model_0.bin'))\n",
    "model1.eval()\n",
    "\n",
    "model2=bertmodel(conf=model_config)\n",
    "model2.to(device)\n",
    "model2.load_state_dict(torch.load('../input/roberta-base-cnn-using-pytorch/model_1.bin'))\n",
    "model2.eval()\n",
    "\n",
    "model3=bertmodel(conf=model_config)\n",
    "model3.to(device)\n",
    "model3.load_state_dict(torch.load('../input/roberta-base-cnn-using-pytorch/model_2.bin'))\n",
    "model3.eval()\n",
    "\n",
    "model4=bertmodel(conf=model_config)\n",
    "model4.to(device)\n",
    "model4.load_state_dict(torch.load('../input/roberta-base-cnn-using-pytorch/model_3.bin'))\n",
    "model4.eval()\n",
    "\n",
    "model5=bertmodel(conf=model_config)\n",
    "model5.to(device)\n",
    "model5.load_state_dict(torch.load('../input/roberta-base-cnn-using-pytorch/model_4.bin'))\n",
    "model5.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba488f780f1a45f883adbb45d04e6b72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=221.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "final_out=[]\n",
    "\n",
    "test_data=BertData(\n",
    "    text=df_test.text.values,\n",
    "    selected_text=df_test.selected_text.values,\n",
    "    sentiment=df_test.sentiment.values\n",
    ")\n",
    "\n",
    "test_data_loader=torch.utils.data.DataLoader(\n",
    "    test_data,\n",
    "    batch_size=VALID_BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=1\n",
    ")\n",
    "\n",
    "with torch.no_grad():\n",
    "    tk0=tqdm(test_data_loader, total=len(test_data_loader))\n",
    "    for ind, d in enumerate(tk0):\n",
    "        ids = d['ids']\n",
    "        text_offset = d['text_offset']\n",
    "        token_type_ids = d['token_type_ids']\n",
    "        target_end = d['target_end']\n",
    "        target_start = d['target_start']\n",
    "        sentiment = d['sentiment']\n",
    "        selected_text = d['selected_text']\n",
    "        masks = d['masks']\n",
    "        orig_text = d['orig_text']\n",
    "        \n",
    "        ids = ids.to(device, dtype=torch.long)\n",
    "        token_type_ids = token_type_ids.to(device, dtype=torch.long)\n",
    "        target_start = target_start.to(device, dtype=torch.long)\n",
    "        target_end = target_end.to(device, dtype=torch.long)\n",
    "        masks = masks.to(device, dtype=torch.long)\n",
    "\n",
    "        out_start1, out_end1 = model1(\n",
    "            ids,\n",
    "            token_type_ids = token_type_ids,\n",
    "            masks = masks\n",
    "            )\n",
    "        out_start2, out_end2 = model2(\n",
    "            ids,\n",
    "            token_type_ids = token_type_ids,\n",
    "            masks = masks\n",
    "            )\n",
    "        out_start3, out_end3 = model3(\n",
    "            ids,\n",
    "            token_type_ids = token_type_ids,\n",
    "            masks = masks\n",
    "            )\n",
    "        out_start4, out_end4 = model4(\n",
    "            ids,\n",
    "            token_type_ids = token_type_ids,\n",
    "            masks = masks\n",
    "            )\n",
    "        out_start5, out_end5 = model5(\n",
    "            ids,\n",
    "            token_type_ids = token_type_ids,\n",
    "            masks = masks\n",
    "            )\n",
    "        out_start=(out_start1 + out_start2 + out_start3 + out_start4 + out_start5)/5\n",
    "        out_end=(out_end1 + out_end2 + out_end3 + out_end4 + out_end5)/5\n",
    "\n",
    "        out_start = torch.softmax(out_start, dim=1).cpu().detach().numpy()\n",
    "        out_end = torch.softmax(out_end, dim=1).cpu().detach().numpy()\n",
    "\n",
    "        for ind, x in enumerate(orig_text):\n",
    "            selected=selected_text[ind]\n",
    "            sentiment1=sentiment[ind]\n",
    "            _, out_sequences=calculate_jaccard(\n",
    "                       x,\n",
    "                       sentiment1,\n",
    "                        selected,\n",
    "                        np.argmax(out_start[ind,:]),\n",
    "                        np.argmax(out_end[ind,:]),\n",
    "                        text_offset[ind]\n",
    "            )\n",
    "            final_out.append(out_sequences)\n",
    "\n",
    "def process(selected):\n",
    "    return ' '.join(set(selected.lower().split()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>selected_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f87dea47db</td>\n",
       "      <td>of the http://twitpic.com/67ezh last session day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>96d74cb729</td>\n",
       "      <td>exciting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eee518ae67</td>\n",
       "      <td>a such shame!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01082688c6</td>\n",
       "      <td>bday! happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33987a8ee5</td>\n",
       "      <td>it!! i like</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                     selected_text\n",
       "0  f87dea47db  of the http://twitpic.com/67ezh last session day\n",
       "1  96d74cb729                                          exciting\n",
       "2  eee518ae67                                     a such shame!\n",
       "3  01082688c6                                       bday! happy\n",
       "4  33987a8ee5                                       it!! i like"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample=pd.read_csv('../input/tweet-sentiment-extraction/sample_submission.csv')\n",
    "sample.loc[:,'selected_text']=final_out\n",
    "sample.selected_text=sample.selected_text.map(process)\n",
    "sample.to_csv('submission.csv',index=False)\n",
    "sample.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0105848322da4292823439e95cbc75b3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1ad4adcbf054468db65d779fd4822081": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2eed1d4952ba4baea8e6cabb8b54627b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "4c74e0f2f49544cbbb19e199cecb939e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "519eb581e84942ec9581ede286fb15d2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_1ad4adcbf054468db65d779fd4822081",
       "placeholder": "​",
       "style": "IPY_MODEL_4c74e0f2f49544cbbb19e199cecb939e",
       "value": " 221/221 [01:54&lt;00:00,  1.93it/s]"
      }
     },
     "655d744e55244c1faf392142e9a42856": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9777e9db5df84b3982a0cd7cd96011e2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_0105848322da4292823439e95cbc75b3",
       "max": 221,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_2eed1d4952ba4baea8e6cabb8b54627b",
       "value": 221
      }
     },
     "ba488f780f1a45f883adbb45d04e6b72": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_9777e9db5df84b3982a0cd7cd96011e2",
        "IPY_MODEL_519eb581e84942ec9581ede286fb15d2"
       ],
       "layout": "IPY_MODEL_655d744e55244c1faf392142e9a42856"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
